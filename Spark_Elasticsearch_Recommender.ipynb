{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark-Elasticsearch-Recommender",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfZqVMRR9pHk",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtmIeoR9mAG",
        "colab_type": "text"
      },
      "source": [
        "## 1. Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByL5sLPXuSOL",
        "colab_type": "text"
      },
      "source": [
        "download pakage and unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkPNpS5E9P6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.0.tar.gz\n",
        "!tar xfz elasticsearch-5.3.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSqRDl2T9QDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd elasticsearch-5.3.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08if5s7huNST",
        "colab_type": "text"
      },
      "source": [
        "install vector-scoring plugin:  \n",
        "The aim of this plugin is to enable real-time scoring of vector-based models, in particular factor-based recommendation models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09fJXWnK-EWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ./bin/elasticsearch-plugin install https://github.com/MLnick/elasticsearch-vector-scoring/releases/download/v5.3.0/elasticsearch-vector-scoring-5.3.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFOLhpDDGHLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!adduser elasticsearch\n",
        "!chown -R elasticsearch elasticsearch-5.3.0\n",
        "!su elasticsearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssa3SmdD-L4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! bin/elasticsearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4kPiwz2-aYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install elasticsearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noS5hLZ5-BrI",
        "colab_type": "text"
      },
      "source": [
        "## 2. Elasticsearch Spark connector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrBQWj8h063O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://download.elastic.co/hadoop/elasticsearch-hadoop-5.3.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcEpM4Iz1BVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip elasticsearch-hadoop-5.3.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3WjJ-Se1F8F",
        "colab_type": "text"
      },
      "source": [
        "## 3. Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T82GgaCT1KGt",
        "colab_type": "text"
      },
      "source": [
        "[dowload](https://spark.apache.org/downloads.html) package and unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDPGkQBw16K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xfz spark-2.2.0-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbuE48V82MbL",
        "colab_type": "text"
      },
      "source": [
        "## 4. Download Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7VNEEL564RP",
        "colab_type": "text"
      },
      "source": [
        "The \"small\" version of the latest MovieLens movie rating dataset, containing about 100,000 ratings, 9,000 movies and 700 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuoFsyE32SgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "%cd data\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUTA57H12yKL",
        "colab_type": "text"
      },
      "source": [
        "client for [The Movie Database API](https://www.themoviedb.org/documentation/api); get an API key from https://www.themoviedb.org/documentation/api "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWPLNxj2wyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tmdbsimple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTeYnLXJ4Pli",
        "colab_type": "text"
      },
      "source": [
        "# Scalable Rcommender systems with Elasticsearch& Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkS66wBP4nmR",
        "colab_type": "text"
      },
      "source": [
        "##1. load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBttPCA77L8_",
        "colab_type": "text"
      },
      "source": [
        "We will be using the following files in the folder ./content/data/ml-latest-small:\n",
        "\n",
        "ratings.csv - movie rating data\\\n",
        "links.csv - external database ids for each movie\\\n",
        "movies.csv - movie title and genres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK_4uyEo4PN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first import a few utility methods that we'll use later on\n",
        "from IPython.display import Image, HTML, display\n",
        "# check PySpark is running\n",
        "spark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_luLSNAU8iQW",
        "colab_type": "text"
      },
      "source": [
        "**load ratings:** (userId, movieId, timestamp, rating given by the user to the movie)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKt3LMVy8Bfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you unzipped the data to a different location than that specified in the Journey setup steps\n",
        "# you can change the path below to point to the correct location\n",
        "PATH_TO_DATA = \"../data/ml-latest-small\"\n",
        "# load ratings data\n",
        "ratings = spark.read.csv(PATH_TO_DATA + \"/ratings.csv\", header=True, inferSchema=True)\n",
        "ratings.cache()\n",
        "print(\"Number of ratings: %i\" % ratings.count())\n",
        "print(\"Sample of ratings:\")\n",
        "ratings.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0uuCHEX9hx1",
        "colab_type": "text"
      },
      "source": [
        "the timestamp is a UNIX timestamp in seconds but Elasticsearch takes timestamp in milliseconds,  \n",
        "so we should convert timestamps to milliseconds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIyypAFv9hXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings = ratings.select(\n",
        "    ratings.userId, ratings.movieId, ratings.rating, (ratings.timestamp.cast(\"long\") * 1000).alias(\"timestamp\"))\n",
        "ratings.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp6pIoE9-Q8k",
        "colab_type": "text"
      },
      "source": [
        "**load movies**: (movieId, title, genres)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORV7saBf-hXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load raw data from CSV\n",
        "raw_movies = spark.read.csv(PATH_TO_DATA + \"/movies.csv\", header=True, inferSchema=True)\n",
        "print(\"Raw movie data:\")\n",
        "raw_movies.show(5, truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU-G6Mui-iAs",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the genres field is a bit tricky to use, as the genres are in the form of one string delimited by the | character: Adventure|Animation|Children|Comedy|Fantasy.\\\n",
        "\n",
        "Create a DataFrame user-defined function (UDF) to extract this delimited string into a list of genres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POFy9uP_-rKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "# define a UDF to convert the raw genres string to an array of genres and lowercase\n",
        "extract_genres = udf(lambda x: x.lower().split(\"|\"), ArrayType(StringType()))\n",
        "# test it out\n",
        "raw_movies.select(\"movieId\", \"title\", extract_genres(\"genres\").alias(\"genres\")).show(5, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeaG4t2RLu35",
        "colab_type": "text"
      },
      "source": [
        "The movie titles contain the year of release. It would be useful to have that as a field in your search index for filtering results (say you want to filter our recommendations to include only more recent movies).\n",
        "\n",
        "Create a UDF to extract the release year from the title using a Python regular expression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DjNzHfRL18a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "# define a UDF to extract the release year from the title, and return the new title and year in a struct type\n",
        "def extract_year_fn(title):\n",
        "    result = re.search(\"\\(\\d{4}\\)\", title)\n",
        "    try:\n",
        "        if result:\n",
        "            group = result.group()\n",
        "            year = group[1:-1]\n",
        "            start_pos = result.start()\n",
        "            title = title[:start_pos-1]\n",
        "            return (title, year)\n",
        "        else:\n",
        "            return (title, 1970)\n",
        "    except:\n",
        "        print(title)\n",
        "\n",
        "extract_year = udf(extract_year_fn,\\\n",
        "                   StructType([StructField(\"title\", StringType(), True),\\\n",
        "                               StructField(\"release_date\", StringType(), True)]))\n",
        "    \n",
        "# test out our function\n",
        "s = \"Jumanji (1995)\"\n",
        "extract_year_fn(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5RhlnHTM5mR",
        "colab_type": "text"
      },
      "source": [
        "create a new DataFrame with the cleaned-up titles, release dates and genres of the movies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LCjh1JsM8-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = raw_movies.select(\n",
        "    \"movieId\", extract_year(\"title\").title.alias(\"title\"),\\\n",
        "    extract_year(\"title\").release_date.alias(\"release_date\"),\\\n",
        "    extract_genres(\"genres\").alias(\"genres\"))\n",
        "print(\"Cleaned movie data:\")\n",
        "movies.show(5, truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM0iKo8NkCCQ",
        "colab_type": "text"
      },
      "source": [
        "Next, join the links.csv data to movies so that there is an id for The Movie Database corresponding to each movie. You can use this id to retrieve movie poster images when displaying your recommendations later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NscMlysdkD65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link_data = spark.read.csv(PATH_TO_DATA + \"/links.csv\", header=True, inferSchema=True)\n",
        "# join movies with links to get TMDB id\n",
        "movie_data = movies.join(link_data, movies.movieId == link_data.movieId)\\\n",
        "    .select(movies.movieId, movies.title, movies.release_date, movies.genres, link_data.tmdbId)\n",
        "num_movies = movie_data.count()\n",
        "print(\"Cleaned movie data with tmdbId links:\")\n",
        "movie_data.show(5, truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNnOmbFPklUr",
        "colab_type": "text"
      },
      "source": [
        "test your access to TMDb API: You should see the Toy Story movie poster displayed inline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgx13n8xkEaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import tmdbsimple as tmdb\n",
        "    # replace this variable with your actual TMdb API key\n",
        "    tmdb.API_KEY = 'YOUR_API_KEY'\n",
        "    print(\"Successfully imported tmdbsimple!\")\n",
        "    # base URL for TMDB poster images\n",
        "    IMAGE_URL = 'https://image.tmdb.org/t/p/w500'\n",
        "    movie_id = movie_data.first().tmdbId\n",
        "    movie_info = tmdb.Movies(movie_id).info()\n",
        "    movie_poster_url = IMAGE_URL + movie_info['poster_path']\n",
        "    display(Image(movie_poster_url, width=200))\n",
        "except Exception:\n",
        "    print(\"Cannot import tmdbsimple, no movie posters will be displayed!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkvF0KHPk7Wa",
        "colab_type": "text"
      },
      "source": [
        "##2. Load data into Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQkVMvClKTA",
        "colab_type": "text"
      },
      "source": [
        "**Note:** *for the purposes of this demo notebook you have started with an existing example dataset and will load that into Elasticsearch. In practice you may write your event data as well as user and item metadata from your application directly into Elasticsearch.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwoE_cDFlRee",
        "colab_type": "text"
      },
      "source": [
        "First test that your Elasticsearch instance is running and you can connect to it using the Python Elasticsearch client."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDCcK47vk_6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "# test your ES instance is running\n",
        "es = Elasticsearch()\n",
        "es.info(pretty=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pGfRshzmz0l",
        "colab_type": "text"
      },
      "source": [
        "###Create an Elasticsearch index with mappings for users, movies and rating events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CECNB-dmmdv",
        "colab_type": "text"
      },
      "source": [
        "In Elasticsearch, an **\"index\"** is roughly similar to a **\"database\"**, while a **\"document type\"** is roughly similar to a **\"table\"** in that database. The **schema** for a document type is called an **index mapping**.\n",
        "\n",
        "While Elasticsearch supports dynamic mapping, it's advisable to specify the mapping explicitly when creating an index if you know what your data looks like.  \n",
        "\n",
        "For the purposes of your recommendation engine, this is also necessary so that you can specify a [custom analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html) for the field that will hold the recommendation \"model\" (that is, the factor vectors). This will ensure the [vector-scoring plugin](https://github.com/MLnick/elasticsearch-vector-scoring) will work correctly.  \n",
        "\n",
        "**References:**  \n",
        "* [Create index request](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html)\\\n",
        "* [Delimited payload filter](https://www.elastic.co/guide/en/elasticsearch/reference/2.4/analysis-delimited-payload-tokenfilter.html)\n",
        "* [Term vectors](https://www.elastic.co/guide/en/elasticsearch/reference/2.4/docs-termvectors.html#_term_information)\n",
        "* [Mapping](https://www.elastic.co/guide/en/elasticsearch/reference/2.4/mapping.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEp4gFqNpvb0",
        "colab_type": "text"
      },
      "source": [
        "Optional:\n",
        "If you are re-running the notebook and have previously created the demo index in Elasticsearch, you should first delete it by un-commenting and running the next cell, before running the index creation cell that follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS7OT3-Lpl8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# es.indices.delete(index=\"demo\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-r9JJu7p2M6",
        "colab_type": "text"
      },
      "source": [
        "create index:\\\n",
        " mapping is for set the schema\\\n",
        " payload\\\n",
        " @model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ac14kQHlUGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_index = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                # this configures the custom analyzer we need to parse vectors such that the scoring\n",
        "                # plugin will work correctly\n",
        "                \"payload_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\":\"whitespace\",\n",
        "                    \"filter\":\"delimited_payload_filter\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"ratings\": {\n",
        "          # this mapping definition sets up the fields for the rating events\n",
        "          \"properties\": {\n",
        "                \"timestamp\": {\n",
        "                    \"type\": \"date\"\n",
        "                },\n",
        "                \"userId\": {\n",
        "                    \"type\": \"integer\"\n",
        "                },\n",
        "                \"movieId\": {\n",
        "                    \"type\": \"integer\"\n",
        "                },\n",
        "                \"rating\": {\n",
        "                    \"type\": \"double\"\n",
        "                }\n",
        "            }  \n",
        "        },\n",
        "        \"users\": {\n",
        "            # this mapping definition sets up the metadata fields for the users\n",
        "            \"properties\": {\n",
        "                \"userId\": {\n",
        "                    \"type\": \"integer\"\n",
        "                },\n",
        "                \"@model\": {\n",
        "                    # this mapping definition sets up the fields for user factor vectors of our model\n",
        "                    \"properties\": {\n",
        "                        \"factor\": {\n",
        "                            \"type\": \"text\",\n",
        "                            \"term_vector\": \"with_positions_offsets_payloads\",\n",
        "                            \"analyzer\" : \"payload_analyzer\"\n",
        "                        },\n",
        "                        \"version\": {\n",
        "                            \"type\": \"keyword\"\n",
        "                        },\n",
        "                        \"timestamp\": {\n",
        "                            \"type\": \"date\"\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"movies\": {\n",
        "            # this mapping definition sets up the metadata fields for the movies\n",
        "            \"properties\": {\n",
        "                \"movieId\": {\n",
        "                    \"type\": \"integer\"\n",
        "                },\n",
        "                \"tmdbId\": {\n",
        "                    \"type\": \"keyword\"\n",
        "                },\n",
        "                \"genres\": {\n",
        "                    \"type\": \"keyword\"\n",
        "                },\n",
        "                \"release_date\": {\n",
        "                    \"type\": \"date\",\n",
        "                    \"format\": \"year\"\n",
        "                },\n",
        "                \"@model\": {\n",
        "                    # this mapping definition sets up the fields for movie factor vectors of our model\n",
        "                    \"properties\": {\n",
        "                        \"factor\": {\n",
        "                            \"type\": \"text\",\n",
        "                            \"term_vector\": \"with_positions_offsets_payloads\",\n",
        "                            \"analyzer\" : \"payload_analyzer\"\n",
        "                        },\n",
        "                        \"version\": {\n",
        "                            \"type\": \"keyword\"\n",
        "                        },\n",
        "                        \"timestamp\": {\n",
        "                            \"type\": \"date\"\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "# create index with the settings and mappings above\n",
        "es.indices.create(index=\"demo\", body=create_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tlXJBn_mxIf",
        "colab_type": "text"
      },
      "source": [
        "### Load Ratings and Movies DataFrames into Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgIPbX1zQNpe",
        "colab_type": "text"
      },
      "source": [
        "First you will write the ratings data to Elasticsearch. Notice that you can simply use the Spark Elasticsearch connector to write a DataFrame with the native Spark datasource API by specifying format(\"es\")\\\n",
        "\n",
        "You've indexed the rating event data into Elasticsearch,\\\n",
        "  * index(database) name: demo\n",
        "  * document type(table) name: ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrFh1qcQNBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write ratings data\n",
        "ratings.write.format(\"es\").save(\"demo/ratings\")\n",
        "# check write went ok\n",
        "print(\"Dataframe count: %d\" % ratings.count())\n",
        "print(\"ES index count:  %d\" % es.count(index=\"demo\", doc_type=\"ratings\")['count'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NtoSPDQ64M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test things out by retrieving a few rating event documents from Elasticsearch\n",
        "es.search(index=\"demo\", doc_type=\"ratings\", q=\"*\", size=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEPmwSAxRxPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you could count the number of ratings events in a given date range\n",
        "# using Elasticsearch's date math in a query string:\n",
        "es.count(index=\"demo\", doc_type=\"ratings\", q=\"timestamp:[2016-01-01 TO 2016-02-01]\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jcklbiipuaK",
        "colab_type": "text"
      },
      "source": [
        "write the movie data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BflDbRAGSDHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write movie data, specifying the DataFrame column to use as the id mapping\n",
        "movie_data.write.format(\"es\").option(\"es.mapping.id\", \"movieId\").save(\"demo/movies\")\n",
        "# check load went ok\n",
        "print(\"Movie DF count: %d\" % movie_data.count())\n",
        "print(\"ES index count: %d\" % es.count(index=\"demo\", doc_type=\"movies\")['count'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LdO04TsSHUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test things out by searching for movies containing \"matrix\" in the title\n",
        "es.search(index=\"demo\", doc_type=\"movies\", q=\"title:matrix\", size=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u91GhShoSI-6",
        "colab_type": "text"
      },
      "source": [
        "##3. Train a recommmender model on the ratings data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STcXM40vNEK3",
        "colab_type": "text"
      },
      "source": [
        "**Alternating Least Squares**\n",
        "\n",
        "use Spark's ALS to train a model on your ratings data from Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSmsUEJxOaKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings_from_es = spark.read.format(\"es\").load(\"demo/ratings\")\n",
        "ratings_from_es.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1SyOSOOw1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import col\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", regParam=0.01, rank=20, seed=12)\n",
        "model = als.fit(ratings_from_es)\n",
        "model.userFactors.show(5)\n",
        "model.itemFactors.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHyaUVh3SQAy",
        "colab_type": "text"
      },
      "source": [
        "## 4. Export ALS user and item factor vectors to Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBDNuxQJPDmT",
        "colab_type": "text"
      },
      "source": [
        "In order to store the model in the correct format for the index mappings set up earlier, you will need to create some utility functions. These functions will allow you to convert the raw vectors (which are equivalent to a Python list in the factor DataFrames above) to the correct delimited string format. This ensures Elasticsearch will parse the vector field in the model correctly using the **delimited token filter custom analyzer** you configured earlier.\n",
        "\n",
        "You will also create a function to convert a vector and related metadata (such as the Spark model id and a timestamp) into a DataFrame field that matches the model field in the Elasticsearch index mapping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxKBIHV3TfCQ",
        "colab_type": "text"
      },
      "source": [
        "### Utility functions for converting factor vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M46YehyKUrP-",
        "colab_type": "text"
      },
      "source": [
        "* [delimited token filter format](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-delimited-payload-tokenfilter.html): \\\n",
        "In this case, user and item factor vectors are indexed using the Delimited Payload Token Filter, e.g. the vector [1.2, 0.1, 0.4, -0.2, 0.3] is indexed as a string: 0|1.2 1|0.1 2|0.4 3|-0.2 4|0.3.\\\n",
        "This stores the vector indices as \"terms\" and the vector values as \"payloads\".\n",
        "\n",
        "* SparkSQL Struct with string-format vector(DataFrame)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyPEXaAhTekY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import udf, lit, current_timestamp, unix_timestamp\n",
        "\n",
        "def convert_vector(x):\n",
        "    '''Convert a list or numpy array to delimited token filter format'''\n",
        "    return \" \".join([\"%s|%s\" % (i, v) for i, v in enumerate(x)])\n",
        "\n",
        "def reverse_convert(s):\n",
        "    '''Convert a delimited token filter format string back to list format'''\n",
        "    return  [float(f.split(\"|\")[1]) for f in s.split(\" \")]\n",
        "\n",
        "def vector_to_struct(x, version, ts):\n",
        "    '''Convert a vector to a SparkSQL Struct with string-format vector and version fields'''\n",
        "    return (convert_vector(x), version, ts)\n",
        "\n",
        "vector_struct = udf(vector_to_struct, \\\n",
        "                    StructType([StructField(\"factor\", StringType(), True), \\\n",
        "                                StructField(\"version\", StringType(), True),\\\n",
        "                                StructField(\"timestamp\", LongType(), True)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeNXXH3gTc04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test out the vector conversion function\n",
        "test_vec = model.userFactors.select(\"features\").first().features\n",
        "print(test_vec)\n",
        "print()\n",
        "print(convert_vector(test_vec))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el99kK-UU3f2",
        "colab_type": "text"
      },
      "source": [
        "###Convert factor vectors to [factor, version, timestamp] form and write to Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUW1euMNU47e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ver = model.uid\n",
        "ts = unix_timestamp(current_timestamp())\n",
        "movie_vectors = model.itemFactors.select(\"id\", vector_struct(\"features\", lit(ver), ts).alias(\"@model\"))\n",
        "movie_vectors.select(\"id\", \"@model.factor\", \"@model.version\", \"@model.timestamp\").show(5)\n",
        "user_vectors = model.userFactors.select(\"id\", vector_struct(\"features\", lit(ver), ts).alias(\"@model\"))\n",
        "user_vectors.select(\"id\", \"@model.factor\", \"@model.version\", \"@model.timestamp\").show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqM_m7HRU89e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write data to ES, use:\n",
        "# - \"id\" as the column to map to ES movie id\n",
        "# - \"update\" write mode for ES, since you want to update new fields only\n",
        "# - \"append\" write mode for Spark\n",
        "movie_vectors.write.format(\"es\") \\\n",
        "    .option(\"es.mapping.id\", \"id\") \\\n",
        "    .option(\"es.write.operation\", \"update\") \\\n",
        "    .save(\"demo/movies\", mode=\"append\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryeC95PjU9wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write data to ES, use:\n",
        "# - \"id\" as the column to map to ES movie id\n",
        "# - \"index\" write mode for ES, since you have not written to the user index previously\n",
        "# - \"append\" write mode for Spark\n",
        "user_vectors.write.format(\"es\") \\\n",
        "    .option(\"es.mapping.id\", \"id\") \\\n",
        "    .option(\"es.write.operation\", \"index\") \\\n",
        "    .save(\"demo/users\", mode=\"append\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77XAMnvubwz6",
        "colab_type": "text"
      },
      "source": [
        "test if the data was written correctly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JA95_rObrxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# search for a particular sci-fi movie\n",
        "es.search(index=\"demo\", doc_type=\"movies\", q=\"star wars phantom menace\", size=1)['hits']['hits'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d1rfJ4wb3cz",
        "colab_type": "text"
      },
      "source": [
        "## 5. Recommend using ES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upl0b-HtcBaq",
        "colab_type": "text"
      },
      "source": [
        "**Function Prepare**\\\n",
        "Now that you have loaded your recommendation model into Elasticsearch, you will generate some recommendations. First, you will need to create a few utility functions for:\n",
        "\n",
        "* Fetching movie posters from TMdb API (optional)\n",
        "* Constructing the Elasticsearch function score query to generate recommendations from your factor model\n",
        "* Given a movie, use this query to find the movies most similar to it\n",
        "* Given a user, use this query to find the movies with the highest predicted rating, to recommend to the user\n",
        "* Display the results as an HTML table in Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3WqP_wVcd35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "\n",
        "def get_poster_url(id):\n",
        "    \"\"\"Fetch movie poster image URL from TMDb API given a tmdbId\"\"\"\n",
        "    IMAGE_URL = 'https://image.tmdb.org/t/p/w500'\n",
        "    try:\n",
        "        import tmdbsimple as tmdb\n",
        "        from tmdbsimple import APIKeyError\n",
        "        try:\n",
        "            movie = tmdb.Movies(id).info()\n",
        "            poster_url = IMAGE_URL + movie['poster_path'] if 'poster_path' in movie and movie['poster_path'] is not None else \"\"\n",
        "            return poster_url\n",
        "        except APIKeyError as ae:\n",
        "            return \"KEY_ERR\"\n",
        "    except Exception as me:\n",
        "        return \"NA\"\n",
        "    \n",
        "    \n",
        "def fn_query(query_vec, q=\"*\", cosine=False):\n",
        "    \"\"\"\n",
        "    Construct an Elasticsearch function score query.\n",
        "    \n",
        "    The query takes as parameters:\n",
        "        - the field in the candidate document that contains the factor vector\n",
        "        - the query vector\n",
        "        - a flag indicating whether to use dot product or cosine similarity (normalized dot product) for scores\n",
        "        \n",
        "    The query vector passed in will be the user factor vector (if generating recommended movies for a user)\n",
        "    or movie factor vector (if generating similar movies for a given movie)\n",
        "    \"\"\"\n",
        "    return {\n",
        "    \"query\": {\n",
        "        \"function_score\": {\n",
        "            \"query\" : { \n",
        "                \"query_string\": {\n",
        "                    \"query\": q\n",
        "                }\n",
        "            },\n",
        "            \"script_score\": {\n",
        "                \"script\": {\n",
        "                        \"inline\": \"payload_vector_score\",\n",
        "                        \"lang\": \"native\",\n",
        "                        \"params\": {\n",
        "                            \"field\": \"@model.factor\",\n",
        "                            \"vector\": query_vec,\n",
        "                            \"cosine\" : cosine\n",
        "                        }\n",
        "                    }\n",
        "            },\n",
        "            \"boost_mode\": \"replace\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def get_similar(the_id, q=\"*\", num=10, index=\"demo\", dt=\"movies\"):\n",
        "    \"\"\"\n",
        "    Given a movie id, execute the recommendation function score query to find similar movies, ranked by cosine similarity\n",
        "    \"\"\"\n",
        "    response = es.get(index=index, doc_type=dt, id=the_id)\n",
        "    src = response['_source']\n",
        "    if '@model' in src and 'factor' in src['@model']:\n",
        "        raw_vec = src['@model']['factor']\n",
        "        # our script actually uses the list form for the query vector and handles conversion internally\n",
        "        query_vec = reverse_convert(raw_vec)\n",
        "        q = fn_query(query_vec, q=q, cosine=True)\n",
        "        results = es.search(index, dt, body=q)\n",
        "        hits = results['hits']['hits']\n",
        "        return src, hits[1:num+1]\n",
        "    \n",
        "    \n",
        "def get_user_recs(the_id, q=\"*\", num=10, index=\"demo\"):\n",
        "    \"\"\"\n",
        "    Given a user id, execute the recommendation function score query to find top movies, ranked by predicted rating\n",
        "    \"\"\"\n",
        "    response = es.get(index=index, doc_type=\"users\", id=the_id)\n",
        "    src = response['_source']\n",
        "    if '@model' in src and 'factor' in src['@model']:\n",
        "        raw_vec = src['@model']['factor']\n",
        "        # our script actually uses the list form for the query vector and handles conversion internally\n",
        "        query_vec = reverse_convert(raw_vec)\n",
        "        q = fn_query(query_vec, q=q, cosine=False)\n",
        "        results = es.search(index, \"movies\", body=q)\n",
        "        hits = results['hits']['hits']\n",
        "        return src, hits[:num]\n",
        "\n",
        "def get_movies_for_user(the_id, num=10, index=\"demo\"):\n",
        "    \"\"\"\n",
        "    Given a user id, get the movies rated by that user, from highest- to lowest-rated.\n",
        "    \"\"\"\n",
        "    response = es.search(index=index, doc_type=\"ratings\", q=\"userId:%s\" % the_id, size=num, sort=[\"rating:desc\"])\n",
        "    hits = response['hits']['hits']\n",
        "    ids = [h['_source']['movieId'] for h in hits]\n",
        "    movies = es.mget(body={\"ids\": ids}, index=index, doc_type=\"movies\", _source_include=['tmdbId', 'title'])\n",
        "    movies_hits = movies['docs']\n",
        "    tmdbids = [h['_source'] for h in movies_hits]\n",
        "    return tmdbids\n",
        "\n",
        "            \n",
        "def display_user_recs(the_id, q=\"*\", num=10, num_last=10, index=\"demo\"):\n",
        "    user, recs = get_user_recs(the_id, q, num, index)\n",
        "    user_movies = get_movies_for_user(the_id, num_last, index)\n",
        "    # check that posters can be displayed\n",
        "    first_movie = user_movies[0]\n",
        "    first_im_url = get_poster_url(first_movie['tmdbId'])\n",
        "    if first_im_url == \"NA\":\n",
        "        display(HTML(\"<i>Cannot import tmdbsimple. No movie posters will be displayed!</i>\"))\n",
        "    if first_im_url == \"KEY_ERR\":\n",
        "        display(HTML(\"<i>Key error accessing TMDb API. Check your API key. No movie posters will be displayed!</i>\"))\n",
        "        \n",
        "    # display the movies that this user has rated highly\n",
        "    display(HTML(\"<h2>Get recommended movies for user id %s</h2>\" % the_id))\n",
        "    display(HTML(\"<h4>The user has rated the following movies highly:</h4>\"))\n",
        "    user_html = \"<table border=0>\"\n",
        "    i = 0\n",
        "    for movie in user_movies:\n",
        "        movie_im_url = get_poster_url(movie['tmdbId'])\n",
        "        movie_title = movie['title']\n",
        "        user_html += \"<td><h5>%s</h5><img src=%s width=150></img></td>\" % (movie_title, movie_im_url)\n",
        "        i += 1\n",
        "        if i % 5 == 0:\n",
        "            user_html += \"</tr><tr>\"\n",
        "    user_html += \"</tr></table>\"\n",
        "    display(HTML(user_html))\n",
        "    # now display the recommended movies for the user\n",
        "    display(HTML(\"<br>\"))\n",
        "    display(HTML(\"<h2>Recommended movies:</h2>\"))\n",
        "    rec_html = \"<table border=0>\"\n",
        "    i = 0\n",
        "    for rec in recs:\n",
        "        r_im_url = get_poster_url(rec['_source']['tmdbId'])\n",
        "        r_score = rec['_score']\n",
        "        r_title = rec['_source']['title']\n",
        "        rec_html += \"<td><h5>%s</h5><img src=%s width=150></img></td><td><h5>%2.3f</h5></td>\" % (r_title, r_im_url, r_score)\n",
        "        i += 1\n",
        "        if i % 5 == 0:\n",
        "            rec_html += \"</tr><tr>\"\n",
        "    rec_html += \"</tr></table>\"\n",
        "    display(HTML(rec_html))\n",
        "\n",
        "    \n",
        "def display_similar(the_id, q=\"*\", num=10, index=\"demo\", dt=\"movies\"):\n",
        "    \"\"\"\n",
        "    Display query movie, together with similar movies and similarity scores, in a table\n",
        "    \"\"\"\n",
        "    movie, recs = get_similar(the_id, q, num, index, dt)\n",
        "    q_im_url = get_poster_url(movie['tmdbId'])\n",
        "    if q_im_url == \"NA\":\n",
        "        display(HTML(\"<i>Cannot import tmdbsimple. No movie posters will be displayed!</i>\"))\n",
        "    if q_im_url == \"KEY_ERR\":\n",
        "        display(HTML(\"<i>Key error accessing TMDb API. Check your API key. No movie posters will be displayed!</i>\"))\n",
        "        \n",
        "    display(HTML(\"<h2>Get similar movies for:</h2>\"))\n",
        "    display(HTML(\"<h4>%s</h4>\" % movie['title']))\n",
        "    if q_im_url != \"NA\":\n",
        "        display(Image(q_im_url, width=200))\n",
        "    display(HTML(\"<br>\"))\n",
        "    display(HTML(\"<h2>People who liked this movie also liked these:</h2>\"))\n",
        "    sim_html = \"<table border=0>\"\n",
        "    i = 0\n",
        "    for rec in recs:\n",
        "        r_im_url = get_poster_url(rec['_source']['tmdbId'])\n",
        "        r_score = rec['_score']\n",
        "        r_title = rec['_source']['title']\n",
        "        sim_html += \"<td><h5>%s</h5><img src=%s width=150></img></td><td><h5>%2.3f</h5></td>\" % (r_title, r_im_url, r_score)\n",
        "        i += 1\n",
        "        if i % 5 == 0:\n",
        "            sim_html += \"</tr><tr>\"\n",
        "    sim_html += \"</tr></table>\"\n",
        "    display(HTML(sim_html))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uogOw84ZcgTB",
        "colab_type": "text"
      },
      "source": [
        "###Recommend\n",
        "#### A. Find similar movies for a given movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXkPYlgjelnW",
        "colab_type": "text"
      },
      "source": [
        "Display query movie, together with similar movies and similarity scores, in a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeFf-4_yehQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_similar(2628, num=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k48nCNtSfA2Y",
        "colab_type": "text"
      },
      "source": [
        "For example, perhaps you want to remove any movies with \"matrix\" in the title from the recommendations. You can do this by simply passing a valid Elasticsearch query string to the recommendation function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnBdFjnOemvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_similar(2628, num=5, q=\"title:(NOT matrix)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xefk_WyMe_Au",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Or you may want to ensure that only valid children's movies are shown to young viewers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEGq1_LgeqzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_similar(1, num=5, q=\"genres:children\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKg_4Kr7fOJo",
        "colab_type": "text"
      },
      "source": [
        "You can construct various queries by passing in a query string as q in the recommendation function above. The documentation for the Elasticsearch [query string query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tSgfLb_fgFF",
        "colab_type": "text"
      },
      "source": [
        "#### B. Find movies to recommend to a user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nPphXgwhNEq",
        "colab_type": "text"
      },
      "source": [
        "Given a user id, execute the recommendation function score query to find top movies, ranked by predicted rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv1E_PaMe8Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_user_recs(12, num=5, num_last=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-FI71Uzgfvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_user_recs(12, num=5, num_last=5, q=\"release_date:[2012 TO *]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9LjReNdqR9J",
        "colab_type": "text"
      },
      "source": [
        "###Reference\n",
        "https://github.com/IBM/elasticsearch-spark-recommender"
      ]
    }
  ]
}